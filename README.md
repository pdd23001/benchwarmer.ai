# ðŸª‘ benchwarmer.ai

**Benchmarking should not be a bottleneck of innovation.**

benchwarmer.ai automates the painful workflow of algorithm benchmarking. Upload your algorithm and the research papers you want to compete against â€” our multi-agent framework extracts algorithms from the papers, generates runnable implementations, executes everything in sandboxed environments, and produces comparison charts. What used to take days now takes minutes.

![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue)
![React](https://img.shields.io/badge/react-19-61DAFB)
![Vite](https://img.shields.io/badge/vite-7-646CFF)
![FastAPI](https://img.shields.io/badge/fastapi-0.109-009688)

---

## Table of Contents

- [How It Works](#how-it-works)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Setup](#setup)
- [Running the App](#running-the-app)
- [API Reference](#api-reference)
- [Environment Variables](#environment-variables)
- [Contributing](#contributing)
- [License](#license)

---

## How It Works

1. **Upload** â€” Drop in your `.py` algorithm and the research papers you want to benchmark against.
2. **Intake** â€” An AI agent (Claude or Nemotron) parses your description and PDFs, classifies the problem, and builds a structured benchmark configuration.
3. **Implementation** â€” Claude generates runnable Python implementations of each challenger algorithm extracted from the papers, then smoke-tests them before they proceed.
4. **Execution** â€” All algorithms run in parallel inside isolated sandboxes (local subprocesses or Modal cloud sandboxes). One crash doesn't take down the benchmark.
5. **Analysis** â€” Results are aggregated into a DataFrame and an AI-powered plot agent generates comparison charts on demand.
6. **Conversation** â€” The entire flow is driven through a multi-turn chat interface. Ask follow-up questions, tweak parameters, re-run with different instances â€” all in natural language.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (Vite + React)                   â”‚
â”‚  ChatPage â”€â”€â–º SSE stream â—„â”€â”€ /api/chat â”€â”€â–º OrchestratorAgent    â”‚
â”‚  Sidebar  â”€â”€â–º REST       â—„â”€â”€ /api/sessions, /api/algorithms     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    FastAPI (uvicorn :8000)
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                      â–¼
  IntakeAgent          ImplementationAgent       PlotAgent
  (problem config)     (code generation)         (visualisations)
        â”‚                     â”‚                      â”‚
        â–¼                     â–¼                      â–¼
  LLM Backends         AlgorithmWrapper          matplotlib
  â”œâ”€ ClaudeBackend      smoke-test â†’ register
  â””â”€ OpenAIBackend
     (Nemotron)               â”‚
                              â–¼
                       BenchmarkRunner
                       â”œâ”€ Local subprocess
                       â””â”€ Modal sandbox (cloud)
```

### Multi-Agent Pipeline

| Agent | Role | Model |
|---|---|---|
| **Orchestrator** | Conversational router â€” dispatches tools based on user intent | Claude Sonnet 4 |
| **Intake** | Parses NL problem descriptions + PDFs into structured configs | Claude Sonnet 4 / Nemotron |
| **Implementation** | Generates `AlgorithmWrapper` subclasses from algorithm specs | Claude Sonnet 4 |
| **Plot** | Generates matplotlib code from NL visualisation requests | Claude Sonnet 4 |

### Execution Modes

- **Local** â€” Each algorithm runs in an isolated subprocess with hard timeout enforcement via `multiprocessing`.
- **Modal** â€” Each algorithm runs in its own [Modal](https://modal.com) cloud sandbox for full isolation, parallel execution, and scalability.

---

## Tech Stack

### Backend (`agent-backend/`)
- **Python 3.10+**
- **FastAPI** + **Uvicorn** â€” API server with SSE streaming
- **Anthropic SDK** â€” Claude Sonnet 4 for all AI agents
- **OpenAI SDK** â€” Nemotron via OpenAI-compatible endpoint (NVIDIA DGX Spark)
- **Modal** â€” Serverless sandboxed execution
- **PyMuPDF** â€” PDF text extraction
- **Pandas / NumPy / NetworkX / SciPy** â€” Graph generation, data processing
- **Matplotlib** â€” Chart generation
- **Pydantic** â€” Data validation and configuration models
- **SQLite** â€” Chat session and algorithm persistence

### Frontend (`frontend-vite/`)
- **React 19** + **TypeScript**
- **Vite 7** â€” Dev server and build tool
- **Tailwind CSS 3** â€” Styling
- **Radix UI** â€” Accessible primitives (dialogs, tooltips, selects, etc.)
- **Recharts** â€” Interactive benchmark charts
- **React Router 7** â€” Client-side routing
- **Lucide React** â€” Icons
- **React Markdown** â€” Rendering LLM responses
- **Axios** â€” HTTP client

---

## Project Structure

```
Benchwarmer.AI/
â”œâ”€â”€ agent-backend/
â”‚   â”œâ”€â”€ server.py                    # FastAPI app â€” SSE chat, REST endpoints
â”‚   â”œâ”€â”€ benchwarmer/
â”‚   â”‚   â”œâ”€â”€ config.py                # Pydantic models (BenchmarkConfig, AlgorithmSpec, etc.)
â”‚   â”‚   â”œâ”€â”€ database.py              # SQLite session/message/algorithm persistence
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # Conversational orchestrator (tool-use loop)
â”‚   â”‚   â”‚   â”œâ”€â”€ intake.py            # NL â†’ structured config agent
â”‚   â”‚   â”‚   â”œâ”€â”€ implementation.py    # Algorithm code generation agent
â”‚   â”‚   â”‚   â”œâ”€â”€ plot.py              # NL â†’ matplotlib visualisation agent
â”‚   â”‚   â”‚   â”œâ”€â”€ backends.py          # LLM abstraction (Claude / Nemotron)
â”‚   â”‚   â”‚   â””â”€â”€ tools.py             # Tool definitions for the orchestrator
â”‚   â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”‚   â”œâ”€â”€ runner.py            # Core benchmark execution engine
â”‚   â”‚   â”‚   â”œâ”€â”€ modal_runner.py      # Modal cloud execution
â”‚   â”‚   â”‚   â””â”€â”€ sandbox_pool.py      # Sandbox lifecycle management
â”‚   â”‚   â”œâ”€â”€ generators/              # Graph instance generators (ErdÅ‘s-RÃ©nyi, etc.)
â”‚   â”‚   â”œâ”€â”€ problem_classes/         # Problem-specific validation & objectives
â”‚   â”‚   â”œâ”€â”€ algorithms/              # AlgorithmWrapper base class
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ loader.py            # Dynamic algorithm loading
â”‚   â”‚       â”œâ”€â”€ sandbox.py           # Local sandbox execution
â”‚   â”‚       â”œâ”€â”€ modal_sandbox.py     # Modal sandbox execution
â”‚   â”‚       â”œâ”€â”€ algorithm_sandbox.py # Algorithm smoke-testing
â”‚   â”‚       â””â”€â”€ benchmark_suites.py  # Standard benchmark instances (DIMACS, BiqMac)
â”‚   â”œâ”€â”€ tests/                       # Pytest test suite
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend-vite/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx                  # Router setup
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â””â”€â”€ ChatPage.tsx         # Main chat interface
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx          # Session management sidebar
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx           # App header
â”‚   â”‚   â”‚   â”œâ”€â”€ BenchmarkChart.tsx   # Recharts visualisation
â”‚   â”‚   â”‚   â”œâ”€â”€ BenchwarmerLogo.tsx  # Animated logo
â”‚   â”‚   â”‚   â”œâ”€â”€ FileViewer.tsx       # File upload preview
â”‚   â”‚   â”‚   â”œâ”€â”€ CodeViewer.tsx       # Algorithm code viewer
â”‚   â”‚   â”‚   â””â”€â”€ chat/               # Chat message components
â”‚   â”‚   â””â”€â”€ hooks/                   # Custom React hooks
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ vercel.json
â”‚
â”œâ”€â”€ SPEC.md                          # Original technical specification
â””â”€â”€ README.md                        # â† You are here
```

---

## Prerequisites

- **Python 3.10+** â€” [python.org](https://www.python.org/downloads/)
- **Node.js 18+** â€” [nodejs.org](https://nodejs.org/)
- **npm** (comes with Node.js)
- **Anthropic API Key** â€” [console.anthropic.com](https://console.anthropic.com/)
- *(Optional)* **Modal account** â€” for cloud sandbox execution ([modal.com](https://modal.com))
- *(Optional)* **NVIDIA DGX Spark** â€” for Nemotron backend

---

## Setup

### 1. Clone the repository

```bash
git clone https://github.com/your-org/Benchwarmer.AI.git
cd Benchwarmer.AI
```

### 2. Backend setup

```bash
cd agent-backend

# Create and activate a virtual environment
python -m venv venv

# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configure environment variables

```bash
# Copy the example env file
cp .env.example .env
```

Edit `.env` and add your API key:

```env
ANTHROPIC_API_KEY=sk-ant-...
```

See [Environment Variables](#environment-variables) for the full list of options.

### 4. Frontend setup

```bash
cd ../frontend-vite

# Install dependencies
npm install
```

---

## Running the App

You need **two terminals** â€” one for the backend, one for the frontend.

### Terminal 1 â€” Backend (FastAPI)

```bash
cd agent-backend

# Activate virtual environment (if not already active)
# Windows:
venv\Scripts\activate
# macOS / Linux:
source venv/bin/activate

# Start the API server on port 8000
python -m uvicorn server:app --reload --port 8000
```

The backend will be available at `http://localhost:8000`.

### Terminal 2 â€” Frontend (Vite)

```bash
cd frontend-vite

# Start the dev server (proxies /api to localhost:8000)
npm run dev
```

The frontend will be available at `http://localhost:5173` (default Vite port).

> **Note:** The Vite dev server is configured to proxy all `/api` requests to `http://localhost:8000`, so both servers work together seamlessly during development.

### Running with Modal (Cloud Sandboxes)

To execute benchmarks in Modal cloud sandboxes instead of local subprocesses:

1. Install and authenticate Modal:
   ```bash
   pip install modal
   modal token new
   ```
2. In the chat UI, select **Modal** as the execution mode when starting a new conversation.

## Environment Variables

Create a `.env` file in `agent-backend/` with the following:

| Variable | Required | Description |
|----------|----------|-------------|
| `ANTHROPIC_API_KEY` | **Yes** | Your Anthropic API key for Claude |
| `NEMOTRON_URL` | No | OpenAI-compatible endpoint for Nemotron (default: `http://10.19.177.52:11434/v1`) |
| `NEMOTRON_MODEL` | No | Nemotron model identifier (default: `hf.co/unsloth/Nemotron-3-Nano-30B-A3B-GGUF:Q4_K_M`) |
| `MODAL_TOKEN_ID` | No | Modal API token ID (for cloud execution) |
| `MODAL_TOKEN_SECRET` | No | Modal API token secret |
